{
    "name": "qwen2_1.5b",
    "num_layers": 28,
    "n_head": 12,
    "hidden_dim": 1536,
    "vocab_size": 151936,
    "max_seq_len": 32768,
    "num_key_value_heads": 2,
    "ffn_embed_dim": 8960,
    "model_type": "qwen2", 
    "mlp_gated_linear_units": true
}